(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{435:function(s,v,a){s.exports=a.p+"assets/img/index.4dae925d.png"},436:function(s,v,a){s.exports=a.p+"assets/img/skiplist.d33d3e94.png"},485:function(s,v,a){"use strict";a.r(v);var _=a(20),t=Object(_.a)({},(function(){var s=this,v=s.$createElement,_=s._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[_("h1",{attrs:{id:"database"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#database"}},[s._v("#")]),s._v(" Database")]),s._v(" "),_("h2",{attrs:{id:"事务特性"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#事务特性"}},[s._v("#")]),s._v(" 事务特性")]),s._v(" "),_("ol",[_("li",[s._v("Atomicity")]),s._v(" "),_("li",[s._v("Consistent")]),s._v(" "),_("li",[s._v("Isolate")]),s._v(" "),_("li",[s._v("Durable")])]),s._v(" "),_("h2",{attrs:{id:"数据库范式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据库范式"}},[s._v("#")]),s._v(" 数据库范式")]),s._v(" "),_("ol",[_("li",[s._v("1NF 列是原子的")]),s._v(" "),_("li",[s._v("2NF 非主属性不能部分依赖主属性")]),s._v(" "),_("li",[s._v("3NF 非主属性间不存在传递依赖")])]),s._v(" "),_("h2",{attrs:{id:"脏读-不可重复读-幻读"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#脏读-不可重复读-幻读"}},[s._v("#")]),s._v(" 脏读，不可重复读，幻读")]),s._v(" "),_("ol",[_("li",[s._v("脏读，A事务还没提交时B事务读取，之后A回滚，B读到脏数据")]),s._v(" "),_("li",[s._v("不可重复读，A事务中会读某个数据多次，B事务在期间修改了数据，A两次读到同一个数据不一致")]),s._v(" "),_("li",[s._v("幻读，A事务修改表中全部数据时，B事务添加了一条数据，A之后发现表中还有未修改数据")])]),s._v(" "),_("h2",{attrs:{id:"隔离级别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#隔离级别"}},[s._v("#")]),s._v(" 隔离级别")]),s._v(" "),_("ol",[_("li",[s._v("读未提交")]),s._v(" "),_("li",[s._v("读已提交，解决脏读")]),s._v(" "),_("li",[s._v("可重复读，解决不可重复读")]),s._v(" "),_("li",[s._v("串行化，解决幻读")])]),s._v(" "),_("h2",{attrs:{id:"各隔离级别加锁情况"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#各隔离级别加锁情况"}},[s._v("#")]),s._v(" 各隔离级别加锁情况")]),s._v(" "),_("ol",[_("li",[s._v("read uncommitted 读不加锁，写排他锁")]),s._v(" "),_("li",[s._v("read committed 每次读mvcc都生成快照，在快照中索引")]),s._v(" "),_("li",[s._v("repeatable read 一次事务只在第一次select生成快照（因为快照只对读操作有效，对写操作无效，所以存在幻读）")]),s._v(" "),_("li",[s._v("serialisable 读写均排他锁")])]),s._v(" "),_("h2",{attrs:{id:"乐观锁和悲观锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#乐观锁和悲观锁"}},[s._v("#")]),s._v(" 乐观锁和悲观锁")]),s._v(" "),_("ol",[_("li",[s._v("乐观锁，每次取数据时认为别人都不会修改，所以不上锁，当提交更新时会判断期间数据有无被他人修改\n"),_("ol",[_("li",[s._v("数据版本，为表增加一个version字段，当读数据时将version字段值一同读出，每次更新数据version+1，当提交时比对version是否过期")]),s._v(" "),_("li",[s._v("时间戳，添加timestamp字段类型，其他同上")]),s._v(" "),_("li",[s._v("乐观锁机制避免了长事务中的数据库加锁开销")])])]),s._v(" "),_("li",[s._v("悲观锁，每次修改数据时都获得锁")])]),s._v(" "),_("h2",{attrs:{id:"innodb的两种行级锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#innodb的两种行级锁"}},[s._v("#")]),s._v(" Innodb的两种行级锁")]),s._v(" "),_("ol",[_("li",[s._v("s锁，共享，允许事务读取一行数据")]),s._v(" "),_("li",[s._v("x锁，排他，允许事务更改一行数据")])]),s._v(" "),_("h2",{attrs:{id:"innodb三种行锁算法实现隔离级别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#innodb三种行锁算法实现隔离级别"}},[s._v("#")]),s._v(" innodb三种行锁算法实现隔离级别")]),s._v(" "),_("ol",[_("li",[s._v("record locks，锁定索引上的单个记录，若未定义索引，innodb会隐式创建一个聚族索引，并引用改索引锁定记录")]),s._v(" "),_("li",[s._v("gap locks，锁定一个范围<>")]),s._v(" "),_("li",[s._v("next-key locks，以上的结合，即锁定范围又锁定本身<= =>")])]),s._v(" "),_("h2",{attrs:{id:"mysql的引擎"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mysql的引擎"}},[s._v("#")]),s._v(" mysql的引擎")]),s._v(" "),_("ol",[_("li",[s._v("INNODB")]),s._v(" "),_("li",[s._v("MYISAM")])]),s._v(" "),_("h2",{attrs:{id:"innodb和myisam区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#innodb和myisam区别"}},[s._v("#")]),s._v(" innodb和myisam区别")]),s._v(" "),_("ol",[_("li",[s._v("InnoDB 支持事务，MyISAM 不支持事务，这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一")]),s._v(" "),_("li",[s._v("InnoDB 支持外键，而 MyISAM 不支持")]),s._v(" "),_("li",[s._v("InnoDB 是聚集索引，MyISAM 是非聚集索引")]),s._v(" "),_("li",[s._v("InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快")]),s._v(" "),_("li",[s._v("InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一")])]),s._v(" "),_("h2",{attrs:{id:"聚族索引和非聚族索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#聚族索引和非聚族索引"}},[s._v("#")]),s._v(" 聚族索引和非聚族索引")]),s._v(" "),_("ol",[_("li",[_("img",{attrs:{src:a(435),alt:"index"}})]),s._v(" "),_("li",[s._v("聚族索引\n"),_("ol",[_("li",[s._v("数据和索引放在一起")]),s._v(" "),_("li",[s._v("一个表仅有一个聚族索引，默认为主键，未定义主键时innodb选择一个唯一的非空索引代替，若没有innodb隐式定义一个主键")])])]),s._v(" "),_("li",[s._v("非聚族索引\n"),_("ol",[_("li",[s._v("数据和索引分离，得到数据要回表查询")])])])]),s._v(" "),_("h2",{attrs:{id:"二级索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二级索引"}},[s._v("#")]),s._v(" 二级索引")]),s._v(" "),_("ol",[_("li",[s._v("二级索引即辅助索引")]),s._v(" "),_("li",[s._v("二级索引最终只能拿到主键id，获取内容还需回表")]),s._v(" "),_("li",[s._v("只需要使用到二级索引的查询，不需要进行回表操作的方式称为覆盖索引\n"),_("ol",[_("li",[s._v("再有索引idx_author_name时，"),_("code",[s._v("select id,author,name from book where author = 'author1';")]),s._v("不回表")]),s._v(" "),_("li",[s._v("主键为a索引为b，c查询where b=10时不会表，查询*也不回表，因为索引包含主键a，同时索引包含b，c")]),s._v(" "),_("li",[_("code",[s._v("select * from book where author='author1';")]),s._v(" select * 会回表")])])])]),s._v(" "),_("h2",{attrs:{id:"索引的实现"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#索引的实现"}},[s._v("#")]),s._v(" 索引的实现")]),s._v(" "),_("ol",[_("li",[s._v("B树 / B+树\n"),_("ol",[_("li",[s._v("B树每个节点可以有多个子树，这样一个节点的内容多，树的层数低，有利于磁盘IO（磁盘每次IO会预读，一次可取到一个节点的内容，减少IO次数）")]),s._v(" "),_("li",[s._v("B+树节点只有索引，层数更低，且每次查询都会落到叶子节点，查询稳定")]),s._v(" "),_("li",[s._v("B+树叶子节点有指向右边兄弟的指针，且最后一层数据按索引排列，这样找到起始节点就可以一直向后读到范围结束")])])]),s._v(" "),_("li",[s._v("hash\n"),_("ol",[_("li",[s._v("hash索引查找 O(1)")]),s._v(" "),_("li",[s._v("hash索引只能用来 = IN <= >=，不能用来范围查询")])])])]),s._v(" "),_("h2",{attrs:{id:"索引适用和不适用的场合"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#索引适用和不适用的场合"}},[s._v("#")]),s._v(" 索引适用和不适用的场合")]),s._v(" "),_("ol",[_("li",[s._v("适用\n"),_("ol",[_("li",[s._v("where子句、group子句中出现的字段，要创建索引")]),s._v(" "),_("li",[s._v("order by子句的字段，要创建索引")]),s._v(" "),_("li",[s._v("统计聚合函数中的字段，要创建索引。比如count(字段) 、max(字段)")])])]),s._v(" "),_("li",[s._v("不适用\n"),_("ol",[_("li",[s._v("1．如果需要取到表中所有记录，则没必要创建索引")]),s._v(" "),_("li",[s._v("对非唯一有大量重复值的字段，没必要创建索引，如性别")]),s._v(" "),_("li",[s._v("经常进行修改、删除等操作的字段，没必要创建索引")]),s._v(" "),_("li",[s._v("记录比较少的表，没必要创建索引")])])])]),s._v(" "),_("h2",{attrs:{id:"最左匹配原则"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#最左匹配原则"}},[s._v("#")]),s._v(" 最左匹配原则")]),s._v(" "),_("ol",[_("li",[s._v("mysql可以建立联合索引（多列的索引）")]),s._v(" "),_("li",[s._v("如果你创建一个联合索引, 那 这个索引的任何前缀都会用于查询, (col1, col2, col3)这个联合索引的所有前缀 就是(col1), (col1, col2), (col1, col2, col3), 包含这些列的查询都会启用索 引查询.")]),s._v(" "),_("li",[s._v("其他所有不在最左前缀里的列都不会启用索引, 即使包含了联合索引里的部分列 也不行. 即上述中的(col2), (col3), (col2, col3) 都不会启用索引去查询")])]),s._v(" "),_("h2",{attrs:{id:"mysql模糊查询"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mysql模糊查询"}},[s._v("#")]),s._v(" mysql模糊查询")]),s._v(" "),_("ol",[_("li",[s._v("SELECT 字段 FROM 表 WHERE 某字段 Like 条件\n"),_("ol",[_("li",[s._v("% 匹配任意个字符")]),s._v(" "),_("li",[s._v("_ 匹配单个字符")])])]),s._v(" "),_("li",[s._v("SELECT 字段 FROM 表 WHERE 某字段 REGEXP 正则表达式")])]),s._v(" "),_("h2",{attrs:{id:"模糊查询与索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#模糊查询与索引"}},[s._v("#")]),s._v(" 模糊查询与索引")]),s._v(" "),_("ol",[_("li",[s._v("like %keyword 索引失效\n"),_("ol",[_("li",[s._v("因为任何字符可以匹配 % 无法查找")]),s._v(" "),_("li",[s._v("可逆序后使用索引，"),_("code",[s._v("select * from xxx where mobile_reverse like reverse('%5678');")]),s._v(" mobile_reverse存储mobile的倒叙文本")])])]),s._v(" "),_("li",[s._v("like keyword% 索引有效")]),s._v(" "),_("li",[s._v("like %keyword% 索引失效，也无法反向索引")])]),s._v(" "),_("h2",{attrs:{id:"mysql主从复制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mysql主从复制"}},[s._v("#")]),s._v(" mysql主从复制")]),s._v(" "),_("ol",[_("li",[s._v("做数据热备，当主库挂掉切换到从库")]),s._v(" "),_("li",[s._v("原理\n"),_("ol",[_("li",[s._v("主数据库的更新事件（update，insert，delete）等事件被写入binlog")]),s._v(" "),_("li",[s._v("从库连接主库")]),s._v(" "),_("li",[s._v("主库新建线程（为每个slave都简历一个），将binlog发送到从库")]),s._v(" "),_("li",[s._v("从库启动后创建io线程将binlog内容写入到relay log（中继日志）")]),s._v(" "),_("li",[s._v("从库创建线程从realylog中，从exec_master_log_pos开始执行命令")])])]),s._v(" "),_("li",[s._v("复制方式\n"),_("ol",[_("li",[s._v("同步复制，等待所有从库复制后主库返回客户端")]),s._v(" "),_("li",[s._v("异步复制，主库执行完请求后理解返回，不等待从库是否接收并执行完")]),s._v(" "),_("li",[s._v("半同步复制，当有一个从库复制后，主库返回客户端")])])])]),s._v(" "),_("h2",{attrs:{id:"主从延迟"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#主从延迟"}},[s._v("#")]),s._v(" 主从延迟")]),s._v(" "),_("ol",[_("li")]),s._v(" "),_("h2",{attrs:{id:"mysql中的log"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mysql中的log"}},[s._v("#")]),s._v(" mysql中的log")]),s._v(" "),_("ol",[_("li",[s._v("重做日志 redo log\n"),_("ol",[_("li",[s._v("作用：确保事务的持久性，防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。")]),s._v(" "),_("li",[s._v("内容：物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。")]),s._v(" "),_("li",[s._v("什么时候产生：事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。")]),s._v(" "),_("li",[s._v("什么时候释放：当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）")])])]),s._v(" "),_("li",[s._v("回滚日志 undo log\n"),_("ol",[_("li",[s._v("作用：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读")]),s._v(" "),_("li",[s._v("内容：逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。")]),s._v(" "),_("li",[s._v("什么时候产生：事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性")]),s._v(" "),_("li",[s._v("什么时候释放：当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间")])])]),s._v(" "),_("li",[s._v("二进制日志 binlog\n"),_("ol",[_("li",[s._v("作用：1 用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步；2用于数据库的基于时间点的还原")]),s._v(" "),_("li",[s._v("内容：逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句；")]),s._v(" "),_("li",[s._v("什么时候产生：事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中；这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘；因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些；这是因为binlog是在事务提交的时候一次性写入的造成的")]),s._v(" "),_("li",[s._v("什么时候释放：binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除")])])])]),s._v(" "),_("h2",{attrs:{id:"mysql命令"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mysql命令"}},[s._v("#")]),s._v(" mysql命令")]),s._v(" "),_("ol",[_("li",[s._v("按条件计数\n"),_("ol",[_("li",[_("code",[s._v("SELECT COUNT(*) FROM")]),s._v("students"),_("code",[s._v("GROUP BY")]),s._v("class_id"),_("code",[s._v("> 25;")])]),s._v(" "),_("li",[_("code",[s._v("SELECT COUNT(*) AS")]),s._v("number"),_("code",[s._v(",")]),s._v("class_id"),_("code",[s._v("> 25 AS")]),s._v("type"),_("code",[s._v("FROM")]),s._v("students"),_("code",[s._v("GROUP BY")]),s._v("class_id"),_("code",[s._v("> 25;")])])])])]),s._v(" "),_("h2",{attrs:{id:"mysql高并发"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mysql高并发"}},[s._v("#")]),s._v(" mysql高并发")]),s._v(" "),_("ol",[_("li",[s._v("读多写少\n"),_("ol",[_("li",[s._v("单个master写，多slave读")])])]),s._v(" "),_("li",[s._v("写多\n"),_("ol",[_("li",[s._v("分库\n"),_("ol",[_("li",[s._v("垂直分库；垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上，而不是一个服务器上")]),s._v(" "),_("li",[s._v("水平分库分表；将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈")])])]),s._v(" "),_("li",[s._v("分表\n"),_("ol",[_("li",[s._v("垂直分表；也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题")]),s._v(" "),_("li",[s._v("水平分表；针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用")])])]),s._v(" "),_("li",[s._v("分库分表后的问题\n"),_("ol",[_("li",[s._v("事务支持；分库分表后，就成了分布式事务了")]),s._v(" "),_("li",[s._v("跨库join；分库分表后表之间的关联操作受限，无法join不同分库的表，也无法join分表粒度不同的表\n"),_("ol",[_("li",[s._v("解决：1.全局表，所有库都拷贝一份 2.系统层组装，分别查出内容后组装")])])])])])])])]),s._v(" "),_("h2",{attrs:{id:"redis-使用场景"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis-使用场景"}},[s._v("#")]),s._v(" redis 使用场景")]),s._v(" "),_("ol",[_("li",[s._v("记录帖子点赞数、点击数、评论数")]),s._v(" "),_("li",[s._v("缓存近期热帖")]),s._v(" "),_("li",[s._v("缓存文章详情信息")]),s._v(" "),_("li",[s._v("记录用户会话信息")])]),s._v(" "),_("h2",{attrs:{id:"redis单线程为什么快"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis单线程为什么快"}},[s._v("#")]),s._v(" redis单线程为什么快")]),s._v(" "),_("ol",[_("li",[s._v("纯内存操作")]),s._v(" "),_("li",[s._v("单线程避免线程上下文切换")]),s._v(" "),_("li",[s._v("io复用，epoll lt模式")]),s._v(" "),_("li",[s._v("Redis 的瓶颈最有可能是机器内存或者网络带宽，而非单线程，既然单线程不是 Redis 的性能瓶颈，并且单线程又比较容易实现，所以 Redis 就选择使用单线程来实现")])]),s._v(" "),_("h2",{attrs:{id:"redis功能"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis功能"}},[s._v("#")]),s._v(" redis功能")]),s._v(" "),_("ol",[_("li",[s._v("数据缓存功能")]),s._v(" "),_("li",[s._v("分布式锁的功能")]),s._v(" "),_("li",[s._v("支持数据持久化")]),s._v(" "),_("li",[s._v("支持事务")]),s._v(" "),_("li",[s._v("支持消息队列")])]),s._v(" "),_("h2",{attrs:{id:"redis数据类型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis数据类型"}},[s._v("#")]),s._v(" redis数据类型")]),s._v(" "),_("ol",[_("li",[s._v("string")]),s._v(" "),_("li",[s._v("hash")]),s._v(" "),_("li",[s._v("list")]),s._v(" "),_("li",[s._v("set")]),s._v(" "),_("li",[s._v("sorted set(zset)")])]),s._v(" "),_("h2",{attrs:{id:"redis对比memcache"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis对比memcache"}},[s._v("#")]),s._v(" redis对比memcache")]),s._v(" "),_("ol",[_("li",[s._v("Memcached 所有的值均是简单的字符串，Redis 支持更为丰富的数据类型")]),s._v(" "),_("li",[s._v("Redis 的速度比 Memcached 要快")]),s._v(" "),_("li",[s._v("Redis 可以持久化")]),s._v(" "),_("li",[s._v("Redis 可以设置过期时间")]),s._v(" "),_("li",[s._v("Redis 支持主从同步")])]),s._v(" "),_("h2",{attrs:{id:"redis淘汰策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis淘汰策略"}},[s._v("#")]),s._v(" redis淘汰策略")]),s._v(" "),_("ol",[_("li",[s._v("noeviction：禁止淘汰数据；")]),s._v(" "),_("li",[s._v("allkeys-lru：尝试回收最少使用的键，使得新添加的数据有空间存放；")]),s._v(" "),_("li",[s._v("volatile-lru：尝试回收最少使用的键，但仅限于在过期集合的键，使得新添加的数据有空间存放；")]),s._v(" "),_("li",[s._v("allkeys-random：回收随机的键使得新添加的数据有空间存放；")]),s._v(" "),_("li",[s._v("volatile-random：回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键；")]),s._v(" "),_("li",[s._v("volatile-ttl：回收在过期集合的键，并且优先回收存活时间较短的键，使得新添加的数据有空间存放")])]),s._v(" "),_("h2",{attrs:{id:"redis持久化的方式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis持久化的方式"}},[s._v("#")]),s._v(" redis持久化的方式")]),s._v(" "),_("ol",[_("li",[s._v("rdb\n"),_("ol",[_("li",[s._v("缺省情况下，redis将数据快照存放在磁盘的二进制文件中dump.rdb")]),s._v(" "),_("li",[s._v("可配置持久化策略如多久快照一次，或手动调用save")]),s._v(" "),_("li",[s._v("实现：redis fork子进程写rdb文件，写完后用新文件代替旧文件")])])]),s._v(" "),_("li",[s._v("AOF\n"),_("ol",[_("li",[s._v("追加的方式写每条写操做到文件")]),s._v(" "),_("li",[s._v("重启时优先使用aof重建")])])]),s._v(" "),_("li",[s._v("对比\n"),_("ol",[_("li",[s._v("RDB需要定时持久化，风险是可能会丢两次持久之间的数据，量可能很大")]),s._v(" "),_("li",[s._v("AOF每秒fsync一次指令硬盘，如果硬盘IO慢，会阻塞父进程；风险是会丢失1秒多的数据；在Rewrite过程中，主进程把指令存到mem-buffer中，最后写盘时会阻塞主进程")])])])]),s._v(" "),_("h2",{attrs:{id:"save-和-bgsave-有什么区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#save-和-bgsave-有什么区别"}},[s._v("#")]),s._v(" SAVE 和 BGSAVE 有什么区别？")]),s._v(" "),_("ol",[_("li",[s._v("SAVE 直接调用 rdbSave 函数（用于 Redis 持久化的函数），阻塞 Redis 主进程，直到保存完成为止，在主进程阻塞期间，服务器不能处理客户端的任何请求；")]),s._v(" "),_("li",[s._v("BGSAVE 则会创建一个子进程，子进程负责调用 rdbSave 函数，并在保存完成之后向主进程发送完成信号，Redis 服务器在 BGSAVE 执行期间仍然可以继续处理客户端的请求")])]),s._v(" "),_("h2",{attrs:{id:"跳表"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#跳表"}},[s._v("#")]),s._v(" 跳表")]),s._v(" "),_("ol",[_("li",[_("img",{attrs:{src:a(436),alt:"skiplist"}})]),s._v(" "),_("li",[s._v("跳跃表是一种基于链表的扩展，跳跃表还是一个链表，是一个有序的链表，在遍历的时候基于比较，但普通链表只能遍历，跳跃表加入了一个层的概念，层级越高元素越少，每次先从高层查找，直到找到合适的位置，从图中可以看到高层的节点远远少于底层的节点数，从而实现了跳跃式查找")])]),s._v(" "),_("h2",{attrs:{id:"redis缓存穿透-缓存击穿和缓存雪崩"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis缓存穿透-缓存击穿和缓存雪崩"}},[s._v("#")]),s._v(" redis缓存穿透，缓存击穿和缓存雪崩")]),s._v(" "),_("ol",[_("li",[s._v("缓存穿透\n"),_("ol",[_("li",[s._v("访问不存在的key，每次请求落在数据库，高并发时挂掉")]),s._v(" "),_("li",[s._v("解决，直把null设为缓存;不管查询数据库是否有数据，都缓存起来，只不过把没有数据的缓存结果的过期时间设置为比较短的一个值，比如 3 分钟")])])]),s._v(" "),_("li",[s._v("缓存击穿\n"),_("ol",[_("li",[s._v("大量数据访问同一个key（如秒杀），缓存过期的瞬间大量请求落在数据库")]),s._v(" "),_("li",[s._v("解决，不过期")])])]),s._v(" "),_("li",[s._v("缓存雪崩\n"),_("ol",[_("li",[s._v("大量key同时过期")]),s._v(" "),_("li",[s._v("解决：随机key的过期时间；热点数据考虑不失效")])])])]),s._v(" "),_("h2",{attrs:{id:"redis-有哪些集群策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis-有哪些集群策略"}},[s._v("#")]),s._v(" Redis 有哪些集群策略")]),s._v(" "),_("ol",[_("li",[s._v("主从策略：1 台机器作为写操作，另外 2 台作为读操作，类似于 MySQL 的主从方式；")]),s._v(" "),_("li",[s._v("哨兵策略：增加 1 台机器作为哨兵，监控 3 台主从机器，当主节点挂机的时候，机器内部进行选举，从集群中从节点里指定一台机器升级为主节点，从而实现高可用。当主节点恢复的时候，加入到从节点中继续提供服务；")]),s._v(" "),_("li",[s._v("集群策略：Redis 3.0 之后增加了集群的概念，可实现多主多从的结构，实现正真的高可用")])]),s._v(" "),_("h2",{attrs:{id:"redis高并发高可用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis高并发高可用"}},[s._v("#")]),s._v(" redis高并发高可用")]),s._v(" "),_("ol",[_("li",[s._v("高并发\n"),_("ol",[_("li",[s._v("单机，主从架构，单master写数据，多slave读数据，读写分离")]),s._v(" "),_("li",[s._v("集群，")])])]),s._v(" "),_("li",[s._v("高可用\n"),_("ol",[_("li",[s._v("哨兵，监视master运行状态，当多数认为master挂了，在slave中投票选出一个master")])])])]),s._v(" "),_("h2",{attrs:{id:"如何保证-redis-的数据一致性"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何保证-redis-的数据一致性"}},[s._v("#")]),s._v(" 如何保证 Redis 的数据一致性")]),s._v(" "),_("ol",[_("li",[s._v("合理设置缓存的过期时间；")]),s._v(" "),_("li",[s._v("新增、更改、删除数据库操作时同步更新 Redis，可以使用事物机制来保证数据的一致性")])]),s._v(" "),_("h2",{attrs:{id:"什么是缓存预热-有几种实现方式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是缓存预热-有几种实现方式"}},[s._v("#")]),s._v(" 什么是缓存预热？有几种实现方式")]),s._v(" "),_("ol",[_("li",[s._v("缓存预热是指系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。")]),s._v(" "),_("li",[s._v("缓存预热的实现方式，可分为以下两种：\n"),_("ol",[_("li",[s._v("数据量不大的时候，工程启动的时候进行加载缓存动作")]),s._v(" "),_("li",[s._v("数据量大的时候，设置一个定时任务脚本，进行缓存的刷新")])])])]),s._v(" "),_("h2",{attrs:{id:"redis-是如何实现同步的"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis-是如何实现同步的"}},[s._v("#")]),s._v(" Redis 是如何实现同步的？")]),s._v(" "),_("ol",[_("li",[s._v("Redis 可以实现主从同步和从从同步。当第一次同步时，主节点做一次 BGSAVE，并同时将后续修改操作记录到内存中，待完成后将 RDB 文件全量同步到复制节点，复制节点接受完成后将 RDB 镜像加载到内存，加载完成后再通知主节点将期间修改的操作记录，同步到复制节点进行重放，这样就完成了同步过程")])]),s._v(" "),_("h2",{attrs:{id:"redis分布式锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis分布式锁"}},[s._v("#")]),s._v(" redis分布式锁")]),s._v(" "),_("ol",[_("li",[s._v("setnx命令，意思就是 set if not exist，如果lockKey不存在，把key存入Redis，保存成功后如果result返回1，表示设置成功，如果非1，表示失败，别的线程已经设置过了。")]),s._v(" "),_("li",[s._v("expire()，设置过期时间，防止死锁，假设，如果一个锁set后，一直不删掉，那这个锁相当于一直存在，产生死锁")]),s._v(" "),_("li",[s._v("加锁总共分两步，第一步jedis.setnx，第二步jedis.expire设置过期时间，setnx与expire不是一个原子操作，如果程序执行完第一步后异常了，第二步jedis.expire(lockKey, expireTime)没有得到执行，相当于这个锁没有过期时间，有产生死锁的可能")]),s._v(" "),_("li",[s._v("将加锁和设置过期时间合二为一，一行代码搞定，原子操作")])]),s._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[_("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Long")]),s._v(" result "),_("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" jedis"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),_("span",{pre:!0,attrs:{class:"token function"}},[s._v("setnx")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lockKey"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" requestId"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("result "),_("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),_("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 第二步：设置过期时间")]),s._v("\n   jedis"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),_("span",{pre:!0,attrs:{class:"token function"}},[s._v("expire")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lockKey"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" expireTime"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" jedis"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),_("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lockKey"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" requestId"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" SET_IF_NOT_EXIST"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" SET_WITH_EXPIRE_TIME"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" expireTime"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),_("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),_("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//加锁成功        ")]),s._v("\n"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("        \n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),_("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),_("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//加锁失败")]),s._v("\n")])]),s._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[s._v("1")]),_("br"),_("span",{staticClass:"line-number"},[s._v("2")]),_("br"),_("span",{staticClass:"line-number"},[s._v("3")]),_("br"),_("span",{staticClass:"line-number"},[s._v("4")]),_("br"),_("span",{staticClass:"line-number"},[s._v("5")]),_("br"),_("span",{staticClass:"line-number"},[s._v("6")]),_("br"),_("span",{staticClass:"line-number"},[s._v("7")]),_("br"),_("span",{staticClass:"line-number"},[s._v("8")]),_("br"),_("span",{staticClass:"line-number"},[s._v("9")]),_("br"),_("span",{staticClass:"line-number"},[s._v("10")]),_("br")])]),_("h2",{attrs:{id:"cap原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#cap原理"}},[s._v("#")]),s._v(" cap原理")]),s._v(" "),_("ol",[_("li",[s._v("CAP原理认为，一个提供数据服务的存储系统无法同时完美的满足\n"),_("ol",[_("li",[s._v("一致性（Consistency，一致性指的是所有节点都能在同一时间返回同一份最新的数据副本")]),s._v(" "),_("li",[s._v("数据可用性（Availability），可用性指的是每次请求都能够返回非错误的响应")]),s._v(" "),_("li",[s._v("分区耐受性（Partition Tolerance），分区容错性指的是服务器间的通信即使在一定时间内无法保持畅通也不会影响系统继续运行")])])]),s._v(" "),_("li",[s._v("Consistency 和 Availability 的矛盾，一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。")])]),s._v(" "),_("h2",{attrs:{id:"raft协议"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#raft协议"}},[s._v("#")]),s._v(" raft协议")]),s._v(" "),_("ol",[_("li",[s._v("raft解决以下三个问题\n"),_("ol",[_("li",[s._v("leader选举：当已有的leader故障时必须选出一个新的leader")]),s._v(" "),_("li",[s._v("日志复制：leader接受来自客户端的命令，记录为日志，并复制给集群中的其他服务器，并强制其他节点的日志与leader保持一致")]),s._v(" "),_("li",[s._v("安全safety措施：通过一些措施确保系统的安全性，如确保所有状态机按照相同顺序执行相同命令的措施")])])]),s._v(" "),_("li",[s._v("Raft协议的每个副本都会处于三种状态之一\n"),_("ol",[_("li",[s._v("Leader：所有请求的处理者，Leader副本接受client的更新请求，本地处理后再同步至多个其他副本")]),s._v(" "),_("li",[s._v("Follower：请求的被动更新者，从Leader接受更新请求，然后写入本地日志文件")]),s._v(" "),_("li",[s._v("Candidate：如果Follower副本在一段时间内没有收到Leader副本的心跳，则判断Leader可能已经故障，此时启动选主过程，此时副本会变成Candidate状态，直到选主结束")]),s._v(" "),_("li",[s._v("开始时大家都是folloer然后拉票，票多的人成为leader，若一次投票没有投出，因为每个follower的等待超时不同，会有先的follower开始第二次选举")])])])])])}),[],!1,null,null,null);v.default=t.exports}}]);